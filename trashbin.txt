
'''
 
show.ShowImage(img,'Before')
 
show.ShowImage(img,'After')
 
show.ShowImage(img)
 
img = tour.DefaultDilateImage(img,threshold_px=None,is_show=True)
 
        if not isinstance(dilate_img,np.ndarray):
            angle = GetSkewAngle(
                img,
                threshold_px=threshold_px,
                is_binary_inv=is_binary_inv,
                is_show=is_show)
        else:
 

    print('kernel',kernel.shape)
 
    show.ShowImage(dilate_img,'Contour.py')
 
    show.ShowImage(dilate_img,'Contour.py')
 
    show.ShowImage(dilate_img,'Contour.py')
 
        show.ShowImage(dilate_img,'Otsu')
 
        show.ShowImage(dilate_img,'Otsu')
 
    print('kernel_area',OddKernelArea(kernel_area))
 
,is_otsu=False
 
dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
 
    print('threshold_px   ',threshold_px   )
    print('kernel         ',kernel         )
    print('kernel_area    ',kernel_area    )
    print('is_binary_inv  ',is_binary_inv  )
    print('is_otsu        ',is_otsu        )
 
    show.ShowImage(dilate_img,'Contour.py')
 
# The best image are ThickFont.jpg and Sharpen.jpg
 
show.SaveText(img_paths[3],'Sharpen')
show.SaveText(img_paths[4],'FFT')
show.SaveText(img_paths[5],'Adaptive')
 
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Sharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/FFTSharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Adaptive.jpg'
 
from Contour import DefaultDi
 

'''
sharp_img = con.Sharpen(thick_img,[-0.5,-0.7])
show.SaveImage(sharp_img,'Sharpen')

fft_img = fft.FFTSharpen03(img,20,20)
show.SaveImage(fft_img,'FFTSharpen')

adapt_img = thresh.AdaptiveBinaryPx02(fft_img)
show.SaveImage(adapt_img,'Adaptive')
'''

# The best image are ThickFont.jpg and Sharpen.jpg
 
                            folder=save_image_folder_and_name[1],
                            fileformat=save_image_folder_and_name[2],
 
                            fileformat=save_image_folder_and_name[2],
 
Dilate
 
Dilate
 
Dilate
 
Dilate
 
Dilate
 
#####################################################################################################################


def SortDefaultContours_Left2Right(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0], reverse = is_reverse)
    return contours

def SortDefaultContours_Top2Bottom(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[1], reverse = is_reverse)
    return contours

def SortDefaultContours_Width(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[2], reverse = is_reverse)
    return contours

def SortDefaultContours_Height(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[3], reverse = is_reverse)
    return contours

def SortDefaultContours_Area(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key = cv2.contourArea, reverse = is_reverse)
    return contours
 
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
 
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
def GetContours_Left2Right(dilate_img,is_reverse=False):
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0], reverse = is_reverse)
    return contours

def GetContours_Top2Bottom(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[1], reverse = is_reverse)
    return contours

def GetContours_Width(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[2], reverse = is_reverse)
    return contours

def GetContours_Height(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[3], reverse = is_reverse)
    return contours

def GetContours_Area(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key = cv2.contourArea, reverse = is_reverse)
    return contours

 
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
 

img = tour.DefaultDilateImage(img,kernel = np.ones((13,3)))
 
'''
contours = tour.GetDefaultContours(img,kernel = np.ones((13,3)),save_image_folder_and_name='ImageWithColumn')#,is_otsu=True,is_binary_inv=True)
ii=0
print('*** contours ***')
for i in contours:
    print('No',ii,'=',i)
    ii+=1
print()
ii=0
print('*** contours ***')
for i in contours:
    print('No',ii,'=',cv2.boundingRect(i))
    ii+=1'''

# show.ShowImage(img)

'''dilate_img = GrayImage(img)

dilate_img = tour.DefaultDilateImage(dilate_img,kernel = np.ones((13,3)))
#show.SaveImage(dilate_img,'DefaultDilateImage13x3')
contour = tour.GetContours(dilate_img)
cnts = cnts[0] if len(cnts) == 2 else cents[1]
# The best Image is the original image.'''
 
#,is_otsu=False)
 
save_image_folder_and_name='ImageWithColumn'
 
            if len(save_image_folder_and_name)==3:
                show.SaveImage(show_img,save_image_folder_and_name[0],f
 
column_
 
show_img = cv2.rectangle(img, (x, y), (x+w, y+h), display_color[count_columns%len(display_color)], 2)
 
    number_of_all_columns=0
 
    ii=0
 
is_otsu=True
 
#####################################################################################################################

def DefaultDilateImage(img,threshold_px=None,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True,is_binary_inv=True):
    dilate_img = GrayImage(img)
    dilate_img = GaussBlur(dilate_img,OddKernelArea(kernel_area))
    if isinstance(threshold_px, (int,float)):
        dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
    if is_otsu==True:
        dilate_img = OtsuBinaryPx(dilate_img,isinverse=is_binary_inv)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
    return dilate_img
 
        is_show=False,
 
is_binary_inv=True
 
is_binary_inv=is_binary_inv
 
        is_binary_inv=True,
 
else:
        
 
display_color=[
        (255,0,0),
        (0,255,0),
        (0,0,255),
    ]
 
(len(ls)+ii)//len(ls)
 
show_img = 
 
#text_result = GetTextFromColumn(img_paths,20,200)
 
def ReadImage(img_path):
    return cv2.imread(img_path)
 
from Utility import Numpy2Image, Image2Numpy,Something
 
    text=GetText(img)
 
FromImage
 
def ReadImage(img_path):
    return cv2.imread(img_path)
 
height
 
200
 
[
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/OriginalImage/img.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/Image/AdaptiveBinary.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/Image/OtsuBinaryPx.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/Image/Sharpen.jpg'
]
 
read.SaveText(img_paths[0],'Original')
read.SaveText(img_paths[1],'AdaptiveBinary')
read.SaveText(img_paths[2],'OtsuBinaryPxt')
read.SaveText(img_paths[3],'Sharpen')
 
Default
 
    else:
        
 
def GetTextFromDefaultColumn(img,height,width,is_a_column=True,is_show=False):
    contours = tour.GetDefaultContours(img)
    text_result = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        if w>width and h>height:
            sub_img = img[y:y+h, x:x+h]
            output = show.GetText(sub_img)
            output = output.split('\n')
            if is_a_column==True:
                text_result.extend(output)
            else:
                text_result.append(output)
    return text_result
 
Default
 
oi
 
,dilate_img
 
        if is_show==True:
            show.ShowImage(output_img,'DrawDilateContours (Original Image)')
 
        if is_show==True:
            show.ShowImage(output_img,'DrawDilateContours (Dilated Image)')
 

def ShowContour(img)
 
eturn 
 
        if is_show == True:
            show.ShowImage(output_img,'DrawDefaultContours (Dilated Image)')
 
        if is_show==True:
            show.ShowImage(output_img,'DrawDefaultContours (Original Image)')
 
output_img = DrawDilateContours(dilate_img=dilate_img,img=img,rgb=rgb)
 
dilate_img = DefaultDilateImage(img,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True)
 
tour.Confession()
 
def Confession():
    print('I used to like Emma.')
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
def SortContours_Bottom2Top():
 
def SortContours_Right2Left():
 
,is_original_img=False
 
,is_original_img=False
 
,is_original_img=False
 
,is_otsu=is_otsu
 
img = RemoveBorders(img)
 
img = RemoveBorders(img)
 
def GetContours(dilate_img):
    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    return contours

def GetLargestContour(dilate_img):
    return GetContours(dilate_img)[0]



 
contours = sorted(contours, key = cv2.contourArea, reverse = True)
 
img = GrayImage(img)
 
show.SaveText(img_paths[4],'FFT')
show.SaveText(img_paths[5],'Sharp')
 
/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img.jpg' ,
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/OtsuBinaryPx.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/ThickFont.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Sharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/FFTSharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Adaptive.jpg'
 
ost_img = thresh.BinaryPx(img)
show.SaveImage(ost_img,'BinaryPx')
 
Otsu
 

thick_img = ThickFont(ost_img)
show.SaveImage(thick_img,'ThickFont')
 
img = Zoom(img_o,1.23)
img = Rotate(img)
 
import sys
ImageProcessingPath = '/Users/imac/Desktop/JOCR_SOBA/ImageProcessing'
sys.path.insert(1, ImageProcessingPath)
# https://stackoverflow.com/questions/4383571/importing-files-from-different-folder

import ShowImage as show
import Threshold as thresh
import RemoveNoise
from FontSize import ThickFont
import Convolution as con
from Rotation import Rotate
from GrayImage import GrayImage
import FFT as fft
from PIL import Image
from Zoom import RemoveBorders,Zoom
import cv2


img_path = [
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_o.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_r.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/OriginalJojoSoba.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/BinaryPx_210.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/jojomeme.jpg'
]
img_o = show.ReadImage(img_path[0])
img = Zoom(img_o,1.23)
img = Rotate(img)
img = GrayImage(img)
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
ost_img = thresh.BinaryPx(img,200)
#show.SaveImage(ost_img,'ost_img')

#fft_img = fft.FFTSharpen01(img,10,10)
#show.SaveImage(fft_img,'fft_img')

thick_img = ThickFont(ost_img)
thick_img = ThickFont(thick_img)
show.ShowImage(thick_img)

#fft_img = fft.FFTBlur03(ost_img,10,10)
#show.ShowImage(fft_img)

#erode_img = con.Sharpen(img)
#erode_img = ThickFont(erode_img)
#show.ShowImage(erode_img)

'''
python3 Preprocess.py 
'''
 
thick_img = ThickFont(thick_img)
 

sharp_img = con.Sharpen(adapt_img)
show.SaveImage(sharp_img,'Sharpen')
 
'''
thick_img = ThickFont(ost_img)
thick_img = ThickFont(thick_img)
show.ShowImage(thick_img)
'''



#fft_img = fft.FFTBlur03(ost_img,10,10)
#show.ShowImage(fft_img)

#erode_img = con.Sharpen(img)
#erode_img = ThickFont(erode_img)
#show.ShowImage(erode_img)

 
sharp_img = con.Sharpen(thick_img,[-0.5,-0.7])
show.SaveImage(sharp_img,'Sharpen')

fft_img = fft.FFTSharpen03(img,20,20)
show.SaveImage(fft_img,'FFTSharpen')

adapt_img = thresh.AdaptiveBinaryPx02(fft_img)
show.SaveImage(adapt_img,'Adaptive')

sharp_img = con.Sharpen(adapt_img)
show.SaveImage(sharp_img,'Sharpen')

'''
thick_img = ThickFont(ost_img)
thick_img = ThickFont(thick_img)
show.ShowImage(thick_img)
'''



#fft_img = fft.FFTBlur03(ost_img,10,10)
#show.ShowImage(fft_img)

#erode_img = con.Sharpen(img)
#erode_img = ThickFont(erode_img)
#show.ShowImage(erode_img)
 
#sharp_img = con.Sharpen(fft_img)
#show.SaveImage(sharp_img,'Sharpen')
 
FFT
 

#ost_img = thresh.BinaryPx(img,200)
#show.SaveImage(ost_img,'ost_img')

fft_img = fft.FFTSharpen01(img,10,10)
show.SaveImage(fft_img,'FFTSharpen01')
 
thick_img = ThickFont(thick_img)
 
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
show.SaveImage(ost_img,'OtsuSet0Px')
 
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
show.SaveImage(ost_img,'OtsuSet0Px')
 
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
show.SaveImage(ost_img,'OtsuSet0Px')
 
/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img.jpg
 
    
 
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_r.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/OriginalJojoSoba.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/BinaryPx_210.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/jojomeme.jpg'
]
 
1
 

    
 
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_r.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/OriginalJojoSoba.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/BinaryPx_210.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/jojomeme.jpg'
]
 
fft_img = ColorImage(fft_img)
 
from PIL import Image
from Zoom import RemoveBorders,Zoom
 
import Threshold as thresh
import RemoveNoise
from FontSize import ThickFont
import Convolution as con
from Rotation import Rotate
from GrayImage import GrayImage
 
original_img = show.ReadImage(img_path[0])
 
    if fileformat[0]=='.':
        fileformat = fileformat[1:]
 
original_img = show.ReadImage(img_path[0])
 
ost_img = thresh.AdaptiveBinaryPx02(thick_img)
show.ShowImage(ost_img)
 
    print(kernel)
 
    print(kernel)
 
#img = con.Sharpen(img)
 
from Contour import DrawDefaultContours
 
img = fft.FFTBlur01(img,180,100)
fft.SaveFFT(img,'JojoBlur100',is_editfft=True)

##img = Zoom(img,1.23)
##img = GrayImage(img)##

##img = Rotate(img,is_show=True)
##show.SaveImage(img,'TestColor02','TestColor')
##print('DrawDefaultContours Activated')
##img = DrawDefaultContours(img,is_original_img=False)
##show.SaveImage(img,'DrawDefaultContours02','TestColor')
 
    text = GetText(img)
 
f not os.path.exists(path):
        #
    else:
        
 
    # 
 
# https://stackoverflow.com/questions/35807605/create-a-file-if-it-doesnt-exist
 

# https://stackoverflow.com/qu
 
if not os.path.exists('/tmp/test'):
    with open('/tmp/test', 'w'): pass
    

 
harpe
 
Rectangle
 
img = fft.ReturnFFT(img)
 
# get grayscale img
def get_grayscale(img):
    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
 
def PrintText():
    pass
 
t
 
01
 

ls=[1,2,3,4]
kernel_area=len(ls)*2+1
kernel = ls[0]*np.ones((kernel_area,kernel_area))
one = np.ones((kernel_area,kernel_area))
center_rows = kernel_area
center_cols = kernel_area
index=kernel_area
ls.pop()
for i in ls:

    mask = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (index,index))
    mask = np.where(mask < 1,mask,i)
    print(mask)
    
    kernel[center_rows-index:center_rows+index, 
         center_cols-index:center_cols+index] = mask.T
    index-=2

print(kernel)
 
    kernel[center_rows-updated_rows:center_rows+updated_rows, 
         center_cols-updated_cols:center_cols+updated_cols] *= mask
 
len(
 
    updated_rows = index
    updated_cols = index
 
s
 
sigma_kernel = np.zeros((kernel_area,kernel_area))
 
    print('kernel.shape',kernel.shape)
    print('index',index)
 
print(mask)
 
    ls=[]
 
ls=[]
 
'''
center_rows =10
center_cols =7
updated_rows=5
updated_cols=6
kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (updated_rows*2, updated_cols*2))
mask = np.zeros((center_rows*2+1,center_cols*2+1), dtype=np.uint8)
mask[center_rows-updated_rows:center_rows+updated_rows, 
    center_cols-updated_cols:center_cols+updated_cols] = kernel.T
mask = np.where(mask < 1,1,0)
print(mask)
 
mask = np.where(mask < 1,1,0)
 
(dft,updated_rows,updated_cols,function_name)
 
(img,threshold_px,is_binary_inv=False,dilate_img=None,kernel = np.ones((2,30)),is_show=False)
 



 
(255,0,0)
 
(255,0,0)
 
print('rgb',rgb)
 
def SaveContours(img,contour,rgb=(255,0,0)):
    SaveImage(img,img_title=)

def SaveDilateContours()

def SaveDefaultContours()
 
    contour = GetContours(dilate_img)
    img = DrawContours(img,rgb,contour)
    return img 
 
dilate_
 
    # Apply default dilate image processing algorithms.
 
 DrawDefaultContours
 
def SaveImageContours
 
rgb
 
'''

def GetSkewAngle(img,threshold_px,is_binary_inv=False,dilate_img=None,kernel = np.ones((2,30)),is_show=False):
    # https://github.com/wjbmattingly/ocr_python_textbook/blob/main/02_02_working%20with%20opencv.ipynb
    # https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df
    new_img = img.copy()
    if not isinstance(dilate_img,np.ndarray):
        dilate_img = DefaultDilateImage(
            new_img,
            threshold_px=threshold_px,
            is_binary_inv=is_binary_inv,
            kernel = kernel)
    largestContour = ReturnLargestContour(dilate_img)
    contour = ReturnContours(dilate_img)
    # https://theailearner.com/tag/cv2-minarearect/
    minAreaRect = cv2.minAreaRect(largestContour)
    angle = minAreaRect[-1]
    if angle < -45:
        angle = 90 + angle
    if angle > 45:
        angle = angle - 90
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    if is_show==True:
        show_img = DrawContours(img,(255,0,0),contour)
        ShowImage(show_img,'Show Contour 01')
        show_img = DrawContours(dilate_img,(255,0,0),contour)
        ShowImage(show_img,'Show Contour 02')    
    return angle

 
    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

 

    #####################################################################################################################

    # 3.rd Find text blocks (contour detect white area)

    # 4.th There can be various approaches to determine skew angle, 
    # but we’ll stick to the simple one — take the largest text block and use its angle.
 

    #####################################################################################################################

    # 5.th calculating angle.
    # The angle value always lies between [-90,0).
 

    #####################################################################################################################
    
    # This is for showing the contours detection.
 
    #####################################################################################################################

 
####def GetSkewAngle(img,threshold_px,is_binary_inv=False,dilate_img=None):
####    # https://github.com/wjbmattingly/ocr_python_textbook/blob/main/02_02_working%20with%20opencv.ipynb
####    # https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df
####
####    #####################################################################################################################
####    
####    # 1.st Step
####    # Convert image to gray image and blur the image to rease noise in the image.
####
####    # 2.nd Step
####    # Then find the area with text 
####    # With a larger kernel on X axis to get rid of all spaces between words, 
####    # and a smaller kernel on Y axis to blend in lines of one block between each other,
####    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
####    # text becomes white (255,255,255), and background is black (0,0,0)
####
####    new_img = img.copy()
####    if not isinstance(dilate_img,np.ndarray):
####        dilate_img = GrayImage(new_img)
####        dilate_img = GaussBlur(dilate_img,9)
####        if isinstance(threshold_px, (int,float)):
####            dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
####        dilate_img = OtsuBinaryPx(dilate_img,isinverse=True)   
####        # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
####        # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
####        kernel = np.ones((2,30))
####        dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
####
####    #####################################################################################################################
####
####    # 3.rd Find text blocks (contour detect white area)
####
####    # 4.th There can be various approaches to determine skew angle, 
####    # but we’ll stick to the simple one — take the largest text block and use its angle.
####
####    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
####    contours = sorted(contours, key = cv2.contourArea, reverse = True)
####    largestContour = contours[0]
####
####    #####################################################################################################################
####
####    # 5.th calculating angle.
####    # The angle value always lies between [-90,0).
####    # https://theailearner.com/tag/cv2-minarearect/
####
####    minAreaRect = cv2.minAreaRect(largestContour)
####    angle = minAreaRect[-1]
####    if angle < -45:
####        angle = 90 + angle
####    if angle > 45:
####        angle = angle - 90
####    
####    #'''    
####    #####################################################################################################################
####    
####    # This is for showing the contours detection.
####    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
####    print('type(new_img)',type(new_img))
####    original_angle = minAreaRect[-1]
####    Folder = 'TestColor'
####    print('angle______________ =',angle)
####    print('original_angle_____ =',original_angle)
####    print('len(contours)______ = ',len(contours))
####    print('len(largestContour) = ',len(largestContour))
####    print('type(dilate_img)',type(dilate_img))
####    ShowImage(dilate_img,'dilate')
####    SaveImage(dilate_img,'dilate_img',Folder)
####    
####    show_img = draw.DrawContours(img,contour=contours,rgb=(255,0,0))
####    ShowImage(show_img,'show_img')
####    SaveImage(show_img,'show_img',Folder)
####    '''cnew_img = ColorImage(new_img)
####    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
####    ShowImage(cnew_img0,'image largestContour')
####    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
####    ShowImage(cnew_img, 'image Contours')
####    SaveImage(cnew_img, 'image Contours',Folder)'''
####
####    '''
####    cdilate_img = ColorImage(dilate_img)
####    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
####    ShowImage(cdilate_img0,'dilate largestContour')
####    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
####    ShowImage(cdilate_img,'dilate Contours')
####    SaveImage(cdilate_img,'cdilate_img',Folder)'''
####    
####    #####################################################################################################################
####    #'''
####
####    return angle

 
    
    #'''    
 
Largest
 
def ReturnContours(dilate_img):
    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    return contours

def ReturnLargestContour(dilate_img):
    return ReturnContours(dilate_img)[0]
 
DrawContours,
 
    #'''
 
,is_show=False
 
    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
 
ilate_img = DefaultDilateImage(img,threshold_px=threshold_px)
 
=None
 
,contour=None
 
if isinstance(contour,list):
        return DrawContours(img,rgb,contour)
    if isinstance(contour,np.ndarray):
        contour = ReturnContours(contour)
        return DrawContours(img,rgb,contour)
    return img 
 
'''
 
ImageProcessing.
 
def DrawContours(img,rgb,contour=None,dilate_img=None,threshold_px=None):
    img = ColorImage(img)
    if isinstance(contour,list):
        img = cv2.drawContours(img, contour, -1, rgb, 3)
        return img
    if isinstance(dilate_img,np.ndarray):
        contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contours = sorted(contours, key = cv2.contourArea, reverse = True)



def DrawContours(img,rgb,dilate_img,contour=None,threshold_px=None,is_binary_inv=False):
    if contour==None:
        contour, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contour = sorted(contour, key = cv2.contourArea, reverse = True)
    img = ColorImage(img)
    img = cv2.drawContours(img, contour, -1, rgb, 3)
    return img 
 
def DrawContours(img,rgb,contour):
    img = ColorImage(img)
    img = cv2.drawContours(img, contour, -1, rgb, 3)
    return img 
 
    return img 

 
    else:
 
contour
 
kernel = np.ones((2,30))
 
def DrawContours(img,rgb,contour=None,dilate_img=None,threshold_px=None,is_binary_inv=False):

    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

    if contour==None:
        new_img = img.copy()
        if not isinstance(dilate_img,np.ndarray):
            dilate_img = GrayImage(new_img)
            dilate_img = GaussBlur(dilate_img,9)
            if isinstance(threshold_px, (int,float)):
                dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
            dilate_img = OtsuBinaryPx(dilate_img,isinverse=True)   
            # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
            # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
            kernel = np.ones((2,30))
            dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
    
    #####################################################################################################################

        # 3.rd Find text blocks (contour detect white area)

        contour, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contour = sorted(contour, key = cv2.contourArea, reverse = True)

    #####################################################################################################################

    # 4.th draw the contour on the image.

    img = ColorImage(img)
    img = cv2.drawContours(img, contour, -1, rgb, 3)
    return img 
 
def ContoursFromDilate(img,)
 
dilate_img=None
 
        new_img = img.copy()
 
if not isinstance(dilate_img,np.ndarray):
 

    #####################################################################################################################

    # 4.th draw the contour on the image.

 
    
    #####################################################################################################################

        # 3.rd Find text blocks (contour detect white area)

 
    
    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

 
or isinstance(dilate_img,np.ndarray)
 
    else:
 
contour,
 
def SaveMarkedImage():
    # https://youtu.be/KrlHXJdiRGE?si=VW6DLUI_hc_b0zHD
    pass
 
img = GrayImage(img)
 
 90 +
 
#img=Zoom(img,zoom=1.23)
'''
show.ShowImage(img)
img=GrayImage(img)
img=RemoveBorders(img)
img=Rotate(img,threshold_px=200)'''
#show.ShowImage(img)
img = GrayImage(img)
#img = fft.ReturnFFT(img,True)
#img = fft.ReturnIFFT(img,True)
fft.SaveFFT(img,'JojoFourier02')
 
    ShowImage(dft)
 
show.SaveImage(img,"JojoFourier04",folder='FFT')
 
    #dft = ((dft*255)**4).astype(np.uint8) 
 
**4)
 
'''
(.venv) imac@iMacs-iMac exPyDH01_Page % python3 Preprocess.py 
Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 639, in _save
    rawmode = RAWMODE[im.mode]
              ~~~~~~~^^^^^^^^^
KeyError: 'F'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Preprocess.py", line 35, in <module>
    fft.SaveFFT(img,'JojoFourier')
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/FFT.py", line 68, in SaveFFT
    SaveImage(dft,img_title,folder=folder,fileformat=fileformat)
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/ShowImage.py", line 33, in SaveImage
    img.save(img_path)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/Image.py", line 2568, in save
    save_handler(self, fp, filename)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 642, in _save
    raise OSError(msg) from e
OSError: cannot write mode F as JPEG
'''
 
img_path = os.path.join(folder,img_title+fileformat)
 
dft.save(img_path)
    #
 
'''
(.venv) imac@iMacs-iMac exPyDH01_Page % python3 Preprocess.py 
Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 639, in _save
    rawmode = RAWMODE[im.mode]
              ~~~~~~~^^^^^^^^^
KeyError: 'F'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Preprocess.py", line 35, in <module>
    fft.SaveFFT(img,'JojoFourier')
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/FFT.py", line 68, in SaveFFT
    SaveImage(dft,img_title,folder=folder,fileformat=fileformat)
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/ShowImage.py", line 33, in SaveImage
    img.save(img_path)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/Image.py", line 2568, in save
    save_handler(self, fp, filename)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 642, in _save
    raise OSError(msg) from e
OSError: cannot write mode F as JPEG
'''
 
#img = fft.ReturnIFFT(img,True)
 
#img=Zoom(img,zoom=1.23)
'''
show.ShowImage(img)
img=GrayImage(img)
img=RemoveBorders(img)
img=Rotate(img,threshold_px=200)'''
 
    #dft = np.abs(dft)
 
    #dft *= 255
    '''print('min_px',dft.min())
    print('max_px',dft.max())
    dft = Numpy2Image(dft)
    if dft.mode != 'RGB':
        dft = dft.convert('RGB')'''
 
    #dft = AdjustFFTForDisplay(dft)
 
NoAdjectment
 
def DisplayFFT()
 
,is_save=False
 
,is_save=False
 
    #dft = dft/dft.max()
 
        #dft = dft/dft.max()
 

def SaveFFT(dft,is_show):
    # https://stackoverflow.com/questions/65369482/issue-with-displaying-dft-output-with-opencvs-imshow
    if is_show==True:
        dft = np.abs(dft)
        #dft = dft/dft.max()
        dft = dft/(255.0**2)
        dft = dft ** (1/4)
        ShowImage(dft)
 
show.ShowImage(img)

#
 
img = fft.FFTSharpen03(img,150,300,is_show=True)
 
def Show
 
print(kernel.shape)
 

    mask = np.where(mask < 1,0,1)
 
    mask = np.zeros((28,29))
    rows = mask.shape[0]
    cols = mask.shape[1]
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
 
img = fft.FFTRSharpen(img,1,1)
 
#img = fft.FFTBlur01(img,192,320,is_show=True)
 
# https://numpy.org/doc/stable/reference/generated/numpy.where.html
    # https://stackoverflow.com/questions/56594598/change-1s-to-0-and-0s-to-1-in-numpy-array-without-looping
    
 
():
    pass

def FFTSharpen02
 
    mask = np.ones((rows,cols), dtype=np.uint8)
    mask[center_rows-updated_rows:center_rows+updated_rows, 
        center_cols-updated_cols:center_cols+updated_cols] *= new_frequency
    dft *= mask
 
'''
 
def FFTSharpen02():
    pass
 
print('kernel')
print(kernel)
 
dft = np.fft.fft2(kernel)#,(20,20))  
print(dft)
dft = np.fft.fft2(kernel,(20,20))  
print(dft)
#dft = np.fft.ifft2(dft)
#img = np.real(dft)
#print(img)
 
dft = np.real(dft).astype(np.int32)
print('dft')
print(dft)
print()
print(np.linalg.det(dft))
print(np.linalg.det(kernel))
 
def FFTExtraHandsWarning(dft,updated_rows,updated_cols,function_name):
    center_rows = math.floor(dft.shape[0]/2)
    center_cols = math.floor(dft.shape[1]/2)
    # https://youtu.be/mI9FIugGIZQ?si=KnaCetRmaAbosYeT
    print('Extra Hands/Legs (Polymelia) : 1 in 1700')
    print('WARNING: updated_rows and/or updated_cols is invalid.')
    print('dft.shape',dft.shape)
    print('center_rows',center_rows)
    print('updated_rows',updated_rows)
    print('center_cols',center_cols)
    print('updated_cols',updated_cols)
    print('Reported by ImageProcessing / FFT.py / def '+function_name)
    print('Reported by ImageProcessing / FFT.py / def FFTExtraHandsWarning(dft,updated_rows,updated_cols,function_name)')
 
warning='FFTRectangleSharpen(dft,updated_rows,updated_cols,new_frequency=0)'
 
    if is_show==True:
 
def ShowFFT01(spectrum):
    # https://stackoverflow.com/questions/65369482/issue-with-displaying-dft-output-with-opencvs-imshow
    mag = np.abs(spectrum)
    #mag = mag/mag.max()
    mag = mag/(255.0**2)
    mag = mag ** (1/4)
    return mag
 
def ShowFFT01(spectrum):
    # https://stackoverflow.com/questions/65369482/issue-with-displaying-dft-output-with-opencvs-imshow
    mag = np.abs(spectrum)
    #mag = mag/mag.max()
    mag = mag/(255.0**2)
    mag = mag ** (1/4)
    return mag
 
    print('mag.max()',mag.max())
 
print('mag.max()',mag.max())
 
        ShowImage(dft)
 
        print('IFFT')
 
*new_frequency
 
    print('Activatied')
 
    #img = 255 * img
 
PrepareSpectrum(dft)
 
max_px=None
 
=None
 
    mag /= mag.max()
 
,scale=0.01
 
/= 100
 
,max_px=None
 
ircle
 

def FFTSharpen02(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass

def FFTBlur01(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass

def FFTBlur02(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass
 
ShowImage.py / def 
 
Return
 
    maximum = mag.max()
 
FFTRSharpe
 
from FFT import FFTRSharpen
 
,mode=0
 
def FFTRSharpen(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass
 
def FFTSharpen01(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass
 
'FFTSharpen01(dft,updated_rows,updated_cols,new_frequency=0)')
 
def FFTCircleSharpen():
    pass
 
    dft[center_rows-updated_rows:center_rows+updated_rows, 
        center_cols-updated_cols:center_cols+updated_cols] = new_frequency
 
mode=0
 
Circle
 
Circle
 
Rect
 
Rect
 
+function_name
 
IsGray(img)
 
    print('updated_rows and/or updated_cols is invalid.')
 
.shape
 
        #print('dft',dft.shape) 
        #print('img',img.shape) 
 
        #
 
Sho
 
_back
 
Sharpen
 
Sharp
 
def ShowImage(img):
    cv2.imshow("image", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
 
def Sharpen(img):
    k2=-0.1
    k1=-5
    k0=-(k2*16+k1*8)+1
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(img, -1, kernel)
 
    ##magnitude_spectrum = 20*np.log(np.abs(fshift))
 
# dft is the array that contains complex numbers.
 

 
 in both the directions. This is simply done by the function, 
 
Now once you got the result, 
 
for analyzing fft
 
2D Graph 
 
* 
* for the sinusoidal signal, if the amplitude varies so fast in short time, you can say it is a high frequency signal. If it varies slowly, it is a low frequency signal. You can extend the same idea to images. Where does the amplitude varies drastically in images ? At the edge points, or noises. So we can say, edges and noises are high frequency contents in an image. If there is no much changes in amplitude, it is a low frequency component. ( Some links are added to Additional Resources_ which explains frequency transform intuitively with examples).

 
varies so 
 
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20*np.log(np.abs(fshift))
 
from Border import Zoom
 
    # The angle value always lies between [-90,0).
    # https://theailearner.com/tag/cv2-minarearect/
 
    if angle > 45:
        angle = -90 + angle
 
    '''
    if angle >= 90:
        angle = angle - 90
    if angle < -90:
        angle = angle + 90
    '''
 
img=GrayImage(img)
img=RemoveBorders(img)
img=Rotate(img,threshold_px=200)
 
from Zoom import Zoom
 
WithoutBorder200_o
 
    #if angle==None:
 
,mode=0
 
dilate_img=None
 
https://github.com/wjbmattingly/ocr_python_textbook
 
img=RemoveBorders(img)
 
# Rotate the image around its center
 
# Rotate the image around its center
 
    SaveImage(dilate_img,'dilate_img',Folder)
 
    SaveImage(dilate_img,'dilate_img',Folder)
 
'''
1. Per usual — convert the image to gray scale and Apply slight blurring to decrease noise in the image.

2. Find areas with text, i.e. text blocks of the image. 
* we will invert and maximize the colors of our image, that will be achieved via thresholding.
* So now text becomes white (exactly 255,255,255 white), and background is black (same deal 0,0,0 black).

3. Find text blocks 
* we need to merge all printed characters of the block by dilation (expansion of white pixels). 
* With a larger kernel on X axis to get rid of all spaces between words, and a smaller kernel on Y axis to blend in lines of one block between each other,
* but keep larger spaces between text blocks intact. (in the original state or similar to that state)

4. Now a simple contour detection with min area rectangle enclosing our contour will form all the text blocks that we need.
* enclode (verb) = surround or close off on all sides.

5. There can be various approaches to determine skew angle, but we’ll stick to the simple one — take the largest text block and use its angle.

'''

 
mode=
 
    '''
 
if mode==0:
            
 
        if mode==1:
            angle = GetSkewAngle_01(img)
 
def GetSkewAngle_01(img):
    # https://github.com/wjbmattingly/ocr_python_textbook/blob/main/02_02_working%20with%20opencv.ipynb
    # https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df

    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

    new_img = img.copy()
    dilate_img = GrayImage(new_img)
    dilate_img = GaussBlur(dilate_img,9)
    dilate_img = BinaryPx(dilate_img,200)   
    dilate_img = OtsuBinaryPx(dilate_img,isinverse=True)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    kernel = np.ones((2,30))
    dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)

    #####################################################################################################################

    # 3.rd Find text blocks (contour detect white area)

    # 4.th There can be various approaches to determine skew angle, 
    # but we’ll stick to the simple one — take the largest text block and use its angle.

    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    largestContour = contours[0]

    #####################################################################################################################

    minAreaRect = cv2.minAreaRect(largestContour)
    angle = minAreaRect[-1]
    if angle >= 90:
        angle = angle - 90
    
    #####################################################################################################################
    
    # This is for showing the contours detection.
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    original_angle = minAreaRect[-1]
    print('angle______________ =',angle)
    print('original_angle_____ =',original_angle)
    print('len(contours)______ = ',len(contours))
    print('len(largestContour) = ',len(largestContour))
    ShowImage(dilate_img,'dilate')
    #SaveImage(dilate_img,'dilate_img_r','RotateImage')
    
    cnew_img = ColorImage(new_img)
    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cnew_img0,'image largestContour')
    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
    ShowImage(cnew_img, 'image Contours')
    #SaveImage(dilate_img,'dilate_img','RotateImage')

    cdilate_img = ColorImage(dilate_img)
    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cdilate_img0,'dilate largestContour')
    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
    ShowImage(cdilate_img,'dilate Contours')
    
    #####################################################################################################################
    
    return angle
 
Otsu
 
    
    '''    
    #####################################################################################################################
    
    # This is for showing the contours detection.
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    original_angle = minAreaRect[-1]
    print('angle______________ =',angle)
    print('original_angle_____ =',original_angle)
    print('len(contours)______ = ',len(contours))
    print('len(largestContour) = ',len(largestContour))
    ShowImage(dilate_img,'dilate')
    SaveImage(dilate_img,'dilate_img_r','RotateImage')
    
    cnew_img = ColorImage(new_img)
    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cnew_img0,'image largestContour')
    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
    ShowImage(cnew_img, 'image Contours')
    #SaveImage(dilate_img,'dilate_img','RotateImage')

    cdilate_img = ColorImage(dilate_img)
    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cdilate_img0,'dilate largestContour')
    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
    ShowImage(cdilate_img,'dilate Contours')
    
    #####################################################################################################################
    '''
 
    SaveImage(dilate_img,'dilate_img_r_2','RotateImage')
 
    SaveImage(dilate_img,'dilate_img_r_1','RotateImage')
 
    SaveImage(dilate_img,'dilate_img_r_0','RotateImage')
 
    SaveImage(dilate_img,'dilate_img_r_0','RotateImage')
 
        if mode==0:
            angle = GetSkewAngle(img)
 
+str(Index)
 
'/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/image_Original.jpg'
 
img_path02 = '/Users/imac/Desktop/JOCR_SOBA/exJojoSoba/IMG_7563.jpeg'
img_path03 = '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/page_01_rotated.jpeg'
 
Index=''
#img=RemoveNoise.RemoveNoise(img)
#img=Threshold.BinaryPx(img,210)

#img=Convolution.Sharpen(img)
#img=Convolution.Sharpen(img)
#img=FontSize.ThickFont(img)
Threshold.BinaryPx(img,200)#,IsInverse=True)
#img=Border.CreateBorders(img,color=[255,0,0],IsGray=False)
 
original_angle = minAreaRect[-1]
 
print('angle',angle)
 
    #####################################################################################################################
    
    # This is for showing the contours detection.
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html

    print('len(contours)       = ',len(contours))
    print('len(largestContour) = ',len(largestContour))
    ShowImage(dilate_img,'dilate')
    
    cnew_img = ColorImage(new_img)
    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cnew_img0,'image largestContour')
    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
    ShowImage(cnew_img, 'image Contours')

    cdilate_img = ColorImage(dilate_img)
    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cdilate_img0,'dilate largestContour')
    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
    ShowImage(cdilate_img,'dilate Contours')
    
    #####################################################################################################################

 
 largestContour
 
    # With a larger kernel on X axis to get rid of all spaces between words, and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
 
    # Find all contours
    '''
    Read this
    * https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html

    Then fix this code
    '''
 

    #####################################################################################################################
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    dilate_img = ColorImage(dilate_img)
    new_img = ColorImage(new_img)
    fdilate_img = cv2.drawContours(dilate_img,  contours[0],-1,  (0,0,255),3)
    fnew_img    = cv2.drawContours(new_img,     contours[0],-1,     (0,0,255),3)
    ShowImage(fdilate_img)
    ShowImage(fnew_img   )    
    #####################################################################################################################

    '''
    ShowImage(dilate_img)
    for c in contours:
        rect = cv2.boundingRect(c)
        x,y,w,h = rect
        cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,0,0),2)
        # cv2.rectangle(dilate_img,(x,y),(x+w,y+h),(150,0,0),2)
        # ShowImage(new_img)'''
    '''
    print('What is contours ?')
    print(len(contours))
    print(len(contours[0]))
    print(len(contours[0][0]))
    print(len(contours[0][0][0]))
    What is contours ?
    28
    241
    1
    2
    '''
    ##print('Show elements of contours.')
    ##for i in contours:
    ##    print(i)
    # Find largest contour and surround in min area box
 
    #cv2.imwrite("temp/boxes.jpg", new_img)
 
    ##for i in range(3):
    ##    largestContour = contours[i]
    ##    rect = cv2.boundingRect(largestContour)
    ##    x,y,w,h = rect
    ##    cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,0,0),2)
    ##    cv2.rectangle(dilate_img,(x,y),(x+w,y+h),(150,0,0),2)
    ##    ShowImage(new_img)
    ##    ShowImage(dilate_img)
 
to obtain skewed image
 
    # Determine the angle. Convert it to the value that was originally used 
 
    #return -1.0 * angle
 
90 + 
 
90 + 
 
    #ShowImage(contours[0])
 
    img_check=img.copy()
 
    img_check=img.copy()
 
#####################################################################################################################
 
    #####################################################################################################################
 
 https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html
 
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
 
    return img
 
    newImage = cvImage.copy()
 
    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
 
    # blur = Convolution.GaussBlur(gray)
 
    # blur = Convolution.GaussBlur(gray)
 
    blur = cv2.GaussianBlur(gray, (9, 9), 0)
 
    # Apply dilate to merge text into meaningful lines/paragraphs.
    # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.
    # But use smaller kernel on Y axis to separate between different blocks of text
 
def Rotate(img,angle):
    img = Numpy2Image(img)
    return img.rotate(angle)
 
Image
 

def Rotate(img,angle):
    img = Numpy2Image(img)
    return img.rotate(angle)

 
def Deskew(cvImage):
    angle = GetSkewAngle(cvImage)
    return RotateImage(cvImage, -1.0 * angle)
 
import PIL
 
def NormalDistribution(x,std=1,mean=0):
    std2=std**2
    coefficient = 1/( (2*np.pi*std2)**(1/2) )
    power = -1*( (x-mean)**2 )/( 2*std2 )
    return coefficient*np.exp(power)

def ChessGaussBlur(img,std=0.1,mean=0.3,kernel_area=3,center_px='None'):
    ls=[]
    for i in range(kernel_area):
        ls.append(NormalDistribution(i,std,mean))
    if center_px.lower() == 'default':
           center_px=center_px
    elif not isinstance(center_px, (int, float)):
        center_px = NormalDistribution(len(ls),std,mean)
    return Sharpen(img,ls,center_px=center_px)

 
'''
img = Input Image 
* (PIL.Image.Image or np.ndarray)

px = Pixel
'''

 
    print('ls',ls)
    print('center_px',center_px)
 
,center_px='None'
 
        print('Hello Ema')
 
    else:
       print('Hello Ami')
 
    if center_px==None:
       center_px=center_px
 
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
 
'''
def Sharpen(img,k0=None,k1=-5,k2=-0.1):
    # Detecting edge
    if k0==None:
        k0=1-(k2*16+k1*8)
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    print(k0)
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(img, -1, kernel)
'''
 
    '''
 
'''
 
'''
 
,effect=10
 
Adaptive
 
* kernel_area = pixel area, must be odd number greater than 1 
    to include both center and border.
 
where it is used for activated
 
 value
 
kernel_area=OddKernelArea(kernel_area)
 
kernel_area=OddKernelArea(kernel_area)
 
img=
 
show.ShowImage(img)
 
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
 
    if k0==None:
        k0=k2
 
k0=None
 
k2=-0.1
 
,210
 
img=Border.CreateBorders(img,color=[255,0,0],IsGray=False)
 
    k1=-5
 
    k2=-0.1
 
def Sharpen(img):
    k2=-0.1
    k1=-5
    k0=-(k2*16+k1*8)+1
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(img, -1, kernel)
 
-> float
 
as bd
 
    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return img
 
color = [255, 255, 255]
top, bottom, left, right = [150]*4

image_with_border = cv2.copyMakeBorder(no_borders, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
cv2.imwrite("temp/image_with_border.jpg", image_with_border)
display("temp/image_with_border.jpg")
 
color = [255, 255, 255]
 
,210
 
ImageProcessing.
 
ImageProcessing.
 
ImageProcessing.
 
import EditImage as edit
 
kernel = np.ones((2,2),np.uint8)
 
import numpy as np
 
    import numpy as np
 
print('Absolute Genderless')
 
# https://stackoverflow.com/questions/60783350/python-fastest-way-to-check-if-image-is-greyscale-or-color
    
 
    img=Numpy2Image(img)
    stat = ImageStat.Stat(img)#.convert("BGR")
 
    # 
 
https://youtu.be/XY9PmBNb3PE?si=Nk8imVOupy4dlSnM
 
        #if grayscale
 
#else its colour
 
#if grayscale
 
 #check the avg with any element value
 
    im = Image.open(path).convert("BGR")
 
kernel = np.ones((1, 1), np.uint8)
 
    kernel = np.ones((1, 1), np.uint8)
 
import numpy as np
 
def Rotate(img,angle):
    img = Numpy2Image(img)
    return img.rotate(angle)
 
    #img=Image2Numpy(img)
 
    # Consider an image with only two distinct image values (bimodal image), 
    # where the histogram would only consist of two peaks. 
    # A good threshold would be in the middle of those two values. 
    # Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
    
    # Limitation of Otsu Method
    # 1. If object area is much smaller compared to background area
    # 2. Image is very noisy
    # 3. Image contains area with different discrete intensities
    # https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR
 
if IsInverse==False:
        
 
    else:
        return cv2.threshold(img,0,max_px,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]
 
    # Consider an image with only two distinct image values (bimodal image), 
    # where the histogram would only consist of two peaks. 
    # A good threshold would be in the middle of those two values. 
    # Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
    
    # Limitation of Otsu Method
    # 1. If object area is much smaller compared to background area
    # 2. Image is very noisy
    # 3. Image contains area with different discrete intensities
    # https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR
 
def AdaptiveOtsuBinaryPx(img,area=10,C=2,max_px=255,IsInverse=False):
    img=GrayImage(img)
    if IsInverse==False:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY+cv2.THRESH_OTSU,area,C)
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU,area,C)

 
tsuBinaryPx
 
        cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,area,C)
        cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY+cv2.THRESH_OTSU,area,C)
 
    # Consider an image with only two distinct image values (bimodal image), 
    # where the histogram would only consist of two peaks. 
    # A good threshold would be in the middle of those two values. 
    # Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
    
    # Limitation of Otsu Method
    # 1. If object area is much smaller compared to background area
    # 2. Image is very noisy
    # 3. Image contains area with different discrete intensities
    # https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR
 
min_px=0
 
def OtsuBinaryPx(img):
    img=GrayImage(img)

 
,IsInverse=False
 
,IsInverse=False
 
def Threshold(img,threshold_px,output_px,Mode='default'):
    # px = pixel
    # https://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/
    # https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html
    # https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576a147222a96556ebc1d948b372bcd7ac59
    img=GrayImage(img)
    if type(Mode)==int:
        Mode=str(Mode)
    if type(Mode)==str:
        
        if 'default' in Mode.lower() or Mode == '1' or ('binary' in Mode.lower() and 'inv' not in Mode.lower()):
            # if px > threshold_px then px = output_px else px = 0
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY)
        
        if Mode == '2' or ('binary' in Mode.lower() and 'inv' in Mode.lower()):
            # if px < threshold_px then px = output_px else px = 0
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY_INV)
        
        if Mode == '3' or ('trunc' in Mode):
            # if px > threshold_px then px = threshold_px else px = px
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_TRUNC)
        
        if Mode == '4' or (('zero' in Mode.lower() or '0' in Mode.lower()) and 'inv' not in Mode.lower()):
            # if px > threshold_px then px = px else px = 0
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_TOZERO)
        
        if Mode == '5' or (('zero' in Mode.lower() or '0' in Mode.lower()) and 'inv' in Mode.lower()):
            # if px > threshold_px then px = 0 else px = px
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_TOZERO_INV)
        
        else:
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY)
    else:
        return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY)
 
video
 
mean
 
def AdaptiveTruncatedPx01(img,area,C=2,max_px=255,IsInverse=False):
    return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_TRUNC,area,C)

def AdaptiveTruncatedPx02(img,area,C=2,max_px=255,IsInverse=False):
    return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_TRUNC,area,C)
 
def AdaptiveBinaryPx01(img,area,C=2,max_px=255,IsInverse=False):
    if IsInverse==False:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,area,C)
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,area,C)

def AdaptiveBinaryPx02(img,area,C=2,max_px=255,IsInverse=False):
    if IsInverse==False:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,area,C)
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,area,C)
 
if IsInverse==False:
        
 
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,area,C)
 
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,area,C)
 
if IsInverse==False:
        
 
v2.THRESH_BINARY
 
Mode=cv2.ADAPTIVE_THRESH_MEAN,
 
,100
 
inaryP
 
    print(img)
 
pilimg = Image.open(img_path)
print(type(img2))
print(show.DescribeImage(img_path,'size'))
img3 = edit.RotateImage(img2,120)
 

show.SaveImage(img3,"Rotate")
 
# if px > threshold_px then px = px else px = 0
 
Threshold
 
_Binary
 
threshold_
 
 == 'default'
 
 not
 
Mode==3
 
==2
 
 in ['default','binary',ss+'binary',ss+' binary',ss+'_binary']
 
    if Mode==0:
        return cv2.threshold(img,dark,light,cv2.THRESH_BINARY)
 
def GrayImage(img):
    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

def InvertedImage(img):
    return cv2.bitwise_not(img)
 
Image
 
Image
 
Image
 
    #kernel = np.array([[-0.1,-0.1,-0.1], [-0.1,1.8,-0.1], [-0.1,-0.1,-0.1]])
    #k3=0    # 24
 
import cv2
import numpy as np
from PIL import Image 
 
,'02'
 
+index
 
,index=''
 
    print('What is type of img ?')
    print(type(img))
    # https://stackoverflow.com/questions/384759/how-do-i-convert-a-pil-image-into-a-numpy-array
    if type(img)!=np.ndarray:
        img=np.array(
            img.getdata()
            ).reshape(
                img.size[0], 
                img.size[1], 
                3)
    print(type(img))
 
Image2
 

show.ShowImage(img3)
 
img3 = edit.RotateImage(img2,120)
 
https://stackoverflow.com/questions/902761/saving-a-numpy-array-as-an-image
 
Image2
 
Numpy2
 
ass
 
def Numpy2Image(img):
    i
    return img
 
if type(folder)==str:
        img_path = folder+'/'+img_title+index+fileformat
    else:
        
 
Image
 
 as ocv
 
Image
 
Image
 

######################################################################################################################
# Create Image
######################################################################################################################

def SaveImage(img,img_title,index='',folder='Image',fileformat='.jpg'):
    # https://stackoverflow.com/questions/902761/saving-a-numpy-array-as-an-image
    if type(folder)==str:
        img_path = folder+'/'+img_title+index+fileformat
    else:
        img_path = img+index+fileformat
    if type(img)==np.ndarray:
        img=Image.fromarray(img)
    img.save(img_path)

 

'''
Name
* img = Image
* Use Lower case for variable.
'''

######################################################################################################################
# Display Image
######################################################################################################################

def Show_Image(img):
    cv2.imshow("image", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def Describe_Image(img_path,detail=None):
    if type(detail)==str:
        if detail.lower() == 'size':
            return Image.open(img_path).size
        elif detail.lower() == 'mode':
            return Image.open(img_path).mode
        elif detail.lower() == 'type':
            return type(Image.open(img_path))
        else:
            return Image.open(img_path)
    else:
        return Image.open(img_path)

def ImportTest():
    print("This is 80000Hours Podcast.")

######################################################################################################################
# Edit Image
######################################################################################################################

 
else:
        
 
Image.save(
 
Folder,
 
def RotateImage(image,angle)
 
print(ocv.Describe_Image(img_path))
print(ocv.Describe_Image(img_path).size)
print(ocv.Describe_Image(img_path,'SIZE'))
print(ocv.Describe_Image(img_path,'Size'))
print(ocv.Describe_Image(img_path,'size'))
print(ocv.Describe_Image(img_path).mode)
print(ocv.Describe_Image(img_path,'Mode'))
print(ocv.Describe_Image(img_path,'MODE'))
print(ocv.Describe_Image(img_path,'mode'))
print(type(ocv.Describe_Image(img_path)))
print(ocv.Describe_Image(img_path,'TYPE'))
print(ocv.Describe_Image(img_path,'Type'))
print(ocv.Describe_Image(img_path,'type'))
 
.mode
 
def Show_Image(img):
    cv2.imshow("image", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def Describe_Image(ImagePath):
    return Image.open(ImagePath)

def ImportTest():
    print("This is 80000Hours Podcast.")
 
    '''
    k0=-0.02    # 19
    k1=-0.05    # 13
    k2=-2     # 8
    k3=18        # 1
    
    kernel = np.array([
        [k0,k0,k0,k0,k0,k0,k0], 
        [k0,k1,k1,k1,k1,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k2,k3,k2,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k1,k1,k1,k1,k0],
        [k0,k0,k0,k0,k0,k0,k0]
        ])'''
    #kernel = np.array([[0.5,0,-0.5], [0.5,0,-0.5], [0.5,0,-0.5]])
    #kernel = (1/(10**2))*np.ones((10,10))
 
print(type(ocv.Describe_Image(img_path)))
for i in ocv.Describe_Image(img_path):
    print(i)
 
print(img)
 
    return 
 

img = cv2.imread('image.jpg')

# get grayscale image
def get_grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# noise removal
def remove_noise(image,n=5):
    return cv2.medianBlur(image,n)
 
#thresholding
def thresholding(image):
    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

#dilation
def dilate(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.dilate(image, kernel, iterations = 1)
    
#erosion
def erode(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.erode(image, kernel, iterations = 1)

#opening - erosion followed by dilation
def opening(image,kernel=None):
    if kernel==None:
        kernel = np.ones((5,5),np.uint8)
    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)

#canny edge detection
def canny(image):
    return cv2.Canny(image, 100, 200)

#skew correction
def deskew(image):
    coords = np.column_stack(np.where(image > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated

#template matching
def match_template(image, template):
    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) 

def sharpen(image):
    #kernel = np.array([[-0.1,-0.1,-0.1], [-0.1,1.8,-0.1], [-0.1,-0.1,-0.1]])
    #k3=0    # 24
    k2=-0.1
    k1=-5
    k0=-(k2*16+k1*8)+1
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    
    '''
    k0=-0.02    # 19
    k1=-0.05    # 13
    k2=-2     # 8
    k3=18        # 1
    
    kernel = np.array([
        [k0,k0,k0,k0,k0,k0,k0], 
        [k0,k1,k1,k1,k1,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k2,k3,k2,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k1,k1,k1,k1,k0],
        [k0,k0,k0,k0,k0,k0,k0]
        ])'''
    #kernel = np.array([[0.5,0,-0.5], [0.5,0,-0.5], [0.5,0,-0.5]])
    #kernel = (1/(10**2))*np.ones((10,10))
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(image, -1, kernel)

def WhiteBackGround(img):
    RangeMax=100
    A1=1
    Step=1
    Start=0
    for i in range(RangeMax):
      mark=np.logical_and(img>Start+(i*Step)/A1,img<Start+((i+1)*Step)/A1)
      img[mark]=Start+(i*Step)/A1
    img[img>=Start+((RangeMax)*Step)/A1]=255
    return img
 
'/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/data01.jpg'
 
'''

ocv.fib()
 
'''
 
Library.
 
OpenCV.py
 
/path/to/application/app/folder
 
/path/to/application/app/folder
 
import exPyDH01_Page.Library.OpenCV as ocv
 
pp.canny(
 
'''
print(output)
print()
print(output['text'])
print()
print(type(output))
print()
print(len(output))
print()
for i in output:
    print(i)
'''
 
['text']
 
    output_type=Output.DICT,
 
#template matching
def match_template(image, template):
    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) 
 
/Users/imac/Desktop/JOCR_Dytecture/Image/JojoSoba/Screen Shot 2024-08-13 at 2.40.58 PM.p
 
.text
 
Ol
 
==1.2.0
 
==8.1.7
 
